PlayData_MachineLearning (2022/12/12)
===========
ananconda ê°€ìƒí™˜ê²½ ìƒì„±

`**conda create -n íŒŒì¼ì´ë¦„ pip python=ë²„ì „**`

ì‹¤í–‰

`**conda activate tf24**`

### í…ì„œí”Œë¡œìš° ì„¤ì¹˜

****************************************************`**pip install tensorflow==2.4**`****************************************************

### ì¼€ë¼ìŠ¤ ì„¤ì¹˜

****************************************************`**pip install keras==2.4**`****************************************************

### ì£¼í”¼í„° ë…¸íŠ¸ë¶ ì„¤ì¹˜

********************`conda install jupyter notebook`********************

### matplotlib ì„¤ì¹˜

**********************************************`**conda install matplotlib**`**********************************************

### scikit-learn ì„¤ì¹˜

******************************************************`pip install scikit-learn`******************************************************

### Scipy ì„¤ì¹˜

********************************`**pip install scipy**`********************************

## AI

- ì¸ê³µì§€ëŠ¥ vs ë¨¸ì‹ ëŸ¬ë‹ vs ë”¥ëŸ¬ë‹
    - ì¸ê³µì§€ëŠ¥>ë¨¸ì‹ ëŸ¬ë‹>ë”¥ëŸ¬ë‹
- **ë¨¸ì‹ ëŸ¬ë‹(ê¸°ê³„í•™ìŠµ)**
    - ë‹¤ì–‘í•œ ëª¨ë¸ ì‚¬ìš©
    - scikit-learn ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
- **ë”¥ëŸ¬ë‹**
    - ë¹„ì •ìš© (ì´ë¯¸ì§€, ì†Œë¦¬)
    - ì¸ê³µ ì‹ ê²½ë§ ê¸°ë°˜ ëª¨ë¸
        - tensorflow
            - DNN
            - CNN(í•©ì„±ê³± ì¸ê³µì‹ ê²½ë§) : ì´ë¯¸ì§€ ë¶„ë¥˜
            - RNN
            - GAN
        - pytorch
- **ë¨¸ì‹ ëŸ¬ë‹**
    - ì§€ë„í•™ìŠµ
        - ë¶„ë¥˜ : ì¢…ë¥˜ ì˜ˆì¸¡
        - íšŒê·€ : ê°’ ì˜ˆì¸¡
    - ë¹„ì§€ë„í•™ìŠµ
        - êµ°ì§‘í™” : ë¹„ìŠ·í•œ ê²ƒë¼ë¦¬ ë¬¶ìŒ
        - ì°¨ì› ì¶•ì†Œ : ì‹œê°í™” ê°€ëŠ¥

## Dataì¢…ë¥˜

**ì •í˜•**

(ë¨¸ì‹ ëŸ¬ë‹, scikit-learn)

- ìˆ˜ì¹˜
    - ì—°ì†í˜• = ì†Œìˆ˜ì 
    - ì´ì‚°í˜• = ì •ìˆ˜
- ë²”ì£¼
    - ëª…ëª©í˜• : ë‚¨, ì—¬
    - ìˆœì„œí˜•(ë¹„êµê°€ëŠ¥) : ëŒ€>ì¤‘>ì†Œ

************ë¹„ì •í˜•************

(ë”¥ëŸ¬ë‹, tensorflow, pytorch)

- ì´ë¯¸ì§€
- ì†Œë¦¬

## scikit-learn

ë¼ì´ë¸ŒëŸ¬ë¦¬ : Machine Learning (ML)

- í´ë˜ìŠ¤ ì œê³µ
    - Estimator
        - `fit()` : í›ˆë ¨
        - `predict()` : ì˜ˆì¸¡
        - Classifier
            - ë¶„ë¥˜ ëª¨ë¸ : ì¢…ë¥˜ ì˜ˆì¸¡
        - Regressor
            - íšŒê·€ ëª¨ë¸ : ê°’ ì˜ˆì¸¡
    
    ### LinearRgression
    
    `**from sklearn.linear_model import LinearRegression**`
    
    - ê¸°ìš¸ê¸°: coef_
    - ì ˆí¸: intercept_

## MLì‹¤ìŠµ ìˆœì„œ

1. **ë°ì´í„° ìˆ˜ì§‘**
    - ì¸í„°ë„· ì´ìš©(í¬ë¡¤ë§ í¬í•¨) â‡’ ê²°ì¸¡ì¹˜, ì´ìƒì¹˜ O
    - ì§ì ‘ ìƒì„±(ë¡œì»¬ Data) â‡’ ê²°ì¸¡ì¹˜, ì´ìƒì¹˜ O
    - í”„ë ˆì„ì›Œí¬(ë¼ì´ë¸ŒëŸ¬ë¦¬) ì œê³µí•œ Data â‡’ ê²°ì¸¡ì¹˜, ì´ìƒì¹˜ X
        - scikit-learn, tensorflow
2. **ë°ì´í„° ì „ì²˜ë¦¬**
    - null ì²˜ë¦¬
    - ì´ìƒì¹˜ ì²˜ë¦¬
    
    <aside>
    ğŸ’¡ **ìŠ¤ì¼€ì¼ë§(scaling)**
    ê°’ì˜ ë²”ìœ„ ë³€ê²½ â‡’ ë‹¨ìœ„ ì¼ì¹˜
    
    </aside>
    
    <aside>
    ğŸ’¡ **ì¸ì½”ë”©(scaling)**
    ë¼ë²¨ì¸ì½”ë”© : ì˜ë¬¸ì â‡’ ìˆ«ì
    **ì›í•«ì¸ì½”ë”© : í‘œí˜„í•˜ê³  ì‹¶ì€ ê°’ì„ 1ë¡œ ë‚˜ë¨¸ì§€ 0ìœ¼ë¡œ**
    
    </aside>
    
3. **ë°ì´í„° ì…‹ ë¶„ë¦¬**
    - í›ˆë ¨ë°ì´í„°(Training Data)
    - í‰ê°€ë°ì´í„°(Test data)
    
    ************ê³¼ì í•©(ë°‘ ë¶€ë¶„ì— ìì„¸íˆ ì„¤ëª…)************
    
    - ê³¼ëŒ€ ì í•©
        - í›ˆë ¨ Data ì •í™•ë„ê°€ ì¢‹ê³  ê·¸ ì´ì™¸ì˜ Data ì •í™•ë„ê°€ ë‚®ìŒ
    - ê³¼ì†Œ ì í•©
        - í›ˆë ¨ Dataì™€ ì´ì™¸ì˜ Data ì •í™•ë„ê°€ ë‚®ìŒ
    - sklearnì˜ train_test_split í•¨ìˆ˜ ì‚¬ìš©
4. **ëª¨ë¸ ìƒì„±**
    - í´ë˜ìŠ¤ ì‚¬ìš©
        
        ì˜ˆ) x = xxxClassifier()
        
        <aside>
        ğŸ’¡ ****************************íŒŒë¼ë¯¸í„° ì¢…ë¥˜
        í•˜ì´í¼ íŒŒë¼ë¯¸í„°** 
        â‡’ ì‚¬ìš©ì ì§€ì •ê°€ëŠ¥
        
        **ëª¨ë¸ íŒŒë¼ë¯¸í„°** 
        â‡’ ì‚¬ìš©ì ì§€ì •x
        â‡’ ëª¨ë¸ì´ í›ˆë ¨(í•™ìŠµ)ì„ í†µí•´ì„œ ì°¾ì•„ì•¼ë˜ëŠ” íŒŒë¼ë¯¸í„°
        â‡’ ëŒ€í‘œì ìœ¼ë¡œ íšŒê·€ê³„ìˆ˜
        
        </aside>
        
5. **ëª¨ë¸ í•™ìŠµ(í›ˆë ¨)**
    
    `**x.fit(Data(feature), ì •ë‹µ(ë ˆì´ë¸”))**` 
    
    - ì§€ë„í•™ìŠµ
    
    <aside>
    ğŸ’¡ **í•­ìƒ Data(feature) = 2ì°¨ì›, ì •ë‹µ(ë ˆì´ë¸”) = 1ì°¨ì›**
    
    </aside>
    
    `**x.fit(Data)**` 
    
    - ë¹„ì§€ë„í•™ìŠµ
    - **ìƒ˜í”Œ(sample), DataPoint** : í•˜ë‚˜ì˜ **í–‰**
    - **íŠ¹ì„±(feature)** : ìƒ˜í”Œì˜ ì†ì„±, ì¦‰ ì—´ì˜ íŠ¹ì„±ì„ ì˜ë¯¸. í†µê³„í•™ì—ì„œëŠ” ë…ë¦½ë³€ìˆ˜(ì„¤ëª…ë³€ìˆ˜)ë¼ê³  í•¨.
    - **ë ˆì´ë¸”(label)** = Data(feature)ì˜ ê°’ì— ëŒ€ì‘ë˜ëŠ” ê°’
    - **í´ë˜ìŠ¤(class)** = ë ˆì´ë¸”(label)ì˜ ì¢…ë¥˜
6. **ì˜ˆì¸¡ ë° í‰ê°€**
    
    `**x.predict()**`
    
    ****************************************************************************************`**kn.score(2ì°¨ì› ë°°ì—´, 1ì°¨ì› ì •ë‹µ)`** 
    
    - ì˜ˆì¸¡ í›„ ìŠ¤ìŠ¤ë¡œ í‰ê°€í•¨
    
    ******************************************************************`**accuracy_score(ì •ë‹µ, ì˜ˆì¸¡ê°’)**`******************************************************************
    
    - ì˜ˆì¸¡í•œ ê°’ì„ `predict()` ë¡œ ì–»ì€ ë’¤ì— í• ë‹¹í•´ ì£¼ì–´ì•¼í•¨.

## ê³¼ì í•©

**ê³¼ëŒ€ì í•©(overfitting)**

- í›ˆë ¨ Dataì—ì„œë§Œ ì˜ˆì¸¡ì„±ëŠ¥ì´ ë†’ê³  ê·¸ ì´ì™¸ì˜ DataëŠ” ì˜ˆì¸¡ ì„±ëŠ¥ì´ ë‚®ì€ ê²½ìš° â‡’ **ì¼ë°˜í™” ì„±ëŠ¥**ì´ ë–¨ì–´ì§

<aside>
â“ **ì´ìœ ?
-** í›ˆë ¨ì„ ë„ˆë¬´ ë§ì´ í•œ ê²½ìš°
- ëª¨ë¸ì´ ë³µì¡í•œ ê²½ìš°

</aside>

<aside>
ğŸ’¡ **í•´ê²° ë°©ì•ˆ
-** í•™ìŠµëŸ‰ì„ ì¤„ì¸ë‹¤
- ëª¨ë¸ ê°„ì†Œí™”

ë¶„ë¥˜: í•˜ì´í¼ íŒŒë¼ë¯¸í„° ìˆ˜ìš©
íšŒê·€: ê·œì œ(regularization)
          L2 ê·œì œ(Ridge) â‡’ ë¦¿ì§€
          L1 ê·œì œ(Lasso) â‡’ ë¼ì˜
          ì—˜ë¼ìŠ¤í‹±ë„·(elastic net) â‡’ L2 + L1

</aside>

******************************ê³¼ì†Œì í•©(underfitting)******************************

- í›ˆë ¨ Data ë° ì´ì™¸ Data ëª¨ë‘ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ë‚®ì€ ê²½ìš°

<aside>
â“ **ì´ìœ ?**
- í›ˆë ¨ì„ ë„ˆë¬´ ì ê²Œ í•œ ê²½ìš°(Dataê°€ ì ì€ ê²½ìš°)
- ëª¨ë¸ ê°„ì†Œí™” ê²½ìš°

</aside>

<aside>
ğŸ’¡ **í•´ê²° ë°©ì•ˆ
-** í•™ìŠµëŸ‰ì„ ëŠ˜ë¦°ë‹¤
- ëª¨ë¸ ë³µì¡í™”

</aside>

### ê·œì œ(ê³¼ëŒ€ì í•© ë°©ì§€)

- **L2 ê·œì œ(Ridge)**
    - íšŒê·€ ê³„ìˆ˜ ê°’ì€ **0ìœ¼ë¡œ ê·¼ì ‘**. ê°’ ê²°ì •ì— ë¯¸ë¯¸í•¨.
- **L1 ê·œì œ(Lasso)**
    - íšŒê·€ ê³„ìˆ˜ ê°’ì„ **0ìœ¼ë¡œ ë§Œë“¤ì–´ë²„ë¦¼**.
- **ì—˜ë¼ìŠ¤í‹±ë„·(elastic net)**
    - L2 + L1

### íšŒê·€(Regression)

**xì— ëŒ€í•œ yì˜ ê°’ ì˜ˆì¸¡**

- ì”ì°¨(residual)ì´ ìµœì†Œê°€ ë˜ê²Œ í•˜ëŠ” ê²ƒ
- ì§ì„ (ê¸°ìš¸ê¸°ì™€ ì ˆí¸)ì„ ì˜ ê·¸ë¦¬ë©´ ëœë‹¤

<aside>
ğŸ’¡ **************************ë‹¨ìˆœíšŒê·€**************************
y = w1(ê¸°ìš¸ê¸°)x+w0(ì ˆí¸)

**featureê°€ ì—¬ëŸ¬ê°œê°€ ë˜ëŠ” ê²½ìš°(ë‹¤ì¤‘íšŒê·€)**
 â‡’ ****y = w1x1 + w2x2 + w3x3 + w4x4 + â€¦ + w0

</aside>

- **ë‹¤í•­ íšŒê·€ ë³€ê²½í•˜ëŠ”ë²• (PolynomialFeatures)**
    
    ```python
    from sklearn.preprocessing import PolynomialFeatures
    
    poly = PolynomialFeatures(degree=2, include_bias=False)
    poly.fit(X_train2D) # => í›ˆë ¨ê°’ í• ë‹¹ (2ì°¨ì›)
    train_poly = poly.transform(X_train2D)
    test_poly = poly.transform(X_test2D)
    ```
    
- ****************ì†ì‹¤í•¨ìˆ˜(ë¹„ìš©í•¨ìˆ˜) â‡’ (cost function, loss function) â†’ ê²½ì‚¬í•˜ê°•ë²•****************
    - **MSE** : ì œê³±ìœ¼ë¡œ ê³„ì‚° â‡’ **ë¯¸ë¶„**ì´ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— ê°€ì¥ ë§ì´ ì‚¬ìš©ëœë‹¤.
    - **MAE** : ì ˆëŒ€ê°’ìœ¼ë¡œ ê³„ì‚°
    - **R**2** : ê²°ì •ê³„ìˆ˜
    - ****************RMSE**************** : MSEì— ë£¨íŠ¸ë¥¼ ì”Œìš´ ê²ƒ

**íŠ¹ì§•**

- ë…ë¦½ì„± : featureë“¤ ê°„ ë…ë¦½ì  â‡’ ìƒê´€ê³„ìˆ˜ ì´ìš©
- ì •ê·œì„± : ì •ê·œë¶„í¬ë”°ë¦„ â‡’ histì´ìš©
- ì„ í˜•ì„± â‡’ ì‹œê°í™”

********í‰ê°€********

`lr.score()` â‡’ ë¶„ë¥˜ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì‚¬ìš©í–ˆë˜ ì •í™•ë„ê°€ ì•„ë‹Œ R2(ê²°ì •ê³„ìˆ˜)ì´ë‹¤.

â‡’ ìƒì„±ëœ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì‹¤ì œê°’ì´ ì˜ í‘œí˜„ë˜ì—ˆëŠ”ì§€ ì•Œë ¤ì£¼ëŠ” ì§€í‘œ.

<aside>
â“ **íšŒê·€ ì•Œê³ ë¦¬ì¦˜ì´ í•™ìŠµí•˜ëŠ” ê²ƒ?**
    â‡’ ê¸°ìš¸ê¸°ì™€ ì ˆí¸ì„ êµ¬í•˜ëŠ” ê²ƒì´ë‹¤.
         `y= W1X + W0`

</aside>

### KNN(K-Nearest Neighbors)

**********************************ê°€ì¥ ê°€ê¹Œìš´ kê°œì˜ ìƒ˜í”Œì—ì„œ ë‹¤ìˆ˜ì˜ í´ë˜ìŠ¤ë¥¼ ê·¸ ìƒ˜í”Œì˜ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡í•œë‹¤.**********************************

- **********ì¥ì **********
    - ì•Œê³ ë¦¬ì¦˜ì´ ê°„ë‹¨í•˜ì—¬ êµ¬í˜„í•˜ê¸° ì‰½ë‹¤.
    - í›ˆë ¨ì´ í•„ìš” ì—†ë‹¤.
    - ìˆ˜ì¹˜ ê¸°ë°˜ ë°ì´í„° ë¶„ë¥˜ ì‘ì—…ì—ì„œ ì„±ëŠ¥ì´ íƒì›”í•˜ë‹¤.
- ********ë‹¨ì ********
    - ë°ì´í„°ì˜ ì–‘ì´ ë§£ì•„ì§€ë©´ ë¶„ë¥˜ ì†ë„ê°€ ëŠë ¤ì§„ë‹¤.
    - ì°¨ì›(ë²¡í„°)ì˜ í¬ê¸°ê°€ í¬ë©´ ê³„ì‚°ëŸ‰ì´ ë§ì•„ì§„ë‹¤.
    - ê±°ë¦¬ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì´ê¸° ë•Œë¬¸ì— ë°˜ë“œì‹œ ********************************ë°ì´í„° í‘œì¤€í™”********************************ë¥¼ í•´ ì£¼ì–´ì•¼ í•œë‹¤.

## ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜(ì¢…ë¥˜ ì˜ˆì¸¡)

### 1. ë°ì´í„° ìˆ˜ì§‘

### 2. ë°ì´í„° ì „ì²˜ë¦¬

### 3. ë°ì´í„° ë¶„ë¦¬ (í›ˆë ¨ë°ì´í„°, í…ŒìŠ¤íŠ¸ë°ì´í„°)

- **train_test_split**

### 4. ìŠ¤ì¼€ì¼ë§(í‘œì¤€í™” : StandardScale)

- `sc = StandardScaled()`
    
    ```python
    sc.transform(x_train)
    sc.transform(x_test)
    sc.transform(new ê°’)
    ```
    

### 5. ëª¨ë¸ ìƒì„± ë° í›ˆë ¨

- `x = xxxclassifier`
    
    ```python
    x.fit(2ì°¨ì› Data, 1ì°¨ì› ë ˆì´ë¸”)
    ```
    

### 6. ì˜ˆì¸¡

- `x.predict(2ì°¨ì›Data)`

### 7. í‰ê°€

- `x.score(data, label)` : ì •í™•ë„

## íšŒê·€ ì•Œê³ ë¦¬ì¦˜(ê°’ ì˜ˆì¸¡)

### 1. ë°ì´í„° ìˆ˜ì§‘

### 2. ë°ì´í„° ì „ì²˜ë¦¬

### 3. ë°ì´í„° ë¶„ë¦¬ (í›ˆë ¨ë°ì´í„°, í…ŒìŠ¤íŠ¸ë°ì´í„°)

- **train_test_split**

### 4. ìŠ¤ì¼€ì¼ë§(í‘œì¤€í™” : StandardScale)

- `sc = StandardScaled()`
    
    ```python
    sc.transform(x_train)
    sc.transform(x_test)
    sc.transform(new ê°’)
    ```
    

### 5. ëª¨ë¸ ìƒì„± ë° í›ˆë ¨

- `x = LinearRegression()`
    
    ```python
    x.fit(2ì°¨ì›Data, 1ì°¨ì› ë ˆì´ë¸”)
    ```
    

### 6. ì˜ˆì¸¡

- `x.predict(2ì°¨ì›Data)`

### 7. í‰ê°€

- `x.score(data, label)` : ì •í™•ë„X â‡’ R**2 (**ê²°ì •ì§€ìˆ˜**)

<aside>
ğŸ’¡ Rì€ ìƒê´€ê³„ìˆ˜(-1 ~ 1)ì´ë‹¤

</aside>

## êµì°¨ ê²€ì¦(Cross Validation)

kfold

- `KFold(n_splits=5, shuffle=False, random_state=None)`
    - n_split : ë°ì´í„°ë¥¼ ëª‡ ë“±ë¶„ìœ¼ë¡œ ë‚˜ëˆŒì§€
    - shuffle: ë°ì´í„° ìˆœì„œ ì„ê¸°
    - random_state: shuffleë¡œ ì„ì€ ë°ì´í„° ê³ ì •í•˜ëŠ” ì—­í• (seed), ê·¼ë° shuffleë¡œ ì‹¤í–‰ë  ë•Œë§ˆë‹¤ ìˆœì„œë¥¼ ì„ì–´ì„œ ê·¸ëŸ°ì§€ ì œ ê¸°ëŠ¥ì„ ëª»í•˜ëŠ” ëª¨ì–‘ì´ë‹¤.

```python
kf = KFold(n_splits=5, shuffle=False, random_state=None)
gen = kf.split(iris_data)

X_train, X_valid =  next(gen) # => generateí•¨ìˆ˜ë¡œ ê°’ì„ í•˜ë‚˜ì”© êº¼ë‚´ì„œ ì‚¬ìš©í•œë‹¤.
X_train, X_valid, len(X_train), len(X_valid)

from sklearn.metrics import accuracy_score
score1_list=[]
score2_list=[]
for train_index, valid_index in kf.split(iris_data): # => ì¸ë±ìŠ¤ê°’ ë¦¬í„´
		# print(train_index, valid_index)
    # ì¸ë±ìŠ¤ì´ìš©í•´ì„œ ì‹¤ì œ ë°ì´í„° ì–»ê¸°
    X_train, X_valid = iris_data[train_index], iris_data[valid_index]
    y_train, y_valid = iris_target[train_index], iris_target[valid_index]
    # ëª¨ë¸ í›ˆë ¨
    dt.fit(X_train, y_train)
    # ì˜ˆì¸¡
    pred = dt.predict(X_valid)
    # í‰ê°€
    score1 = dt.score(X_valid, y_valid)
    score2 = accuracy_score(y_valid, pred)
    
    score1_list.append(score1)
    score2_list.append(score2)    

print(score1_list)
print(score2_list)
print("í‰ê· ", np.mean(score1_list))
```

**stratified Fold (ë¶ˆê· í˜• ë°ì´í„°ì— ì‚¬ìš©)**

```python
from sklearn.model_selection import StratifiedKFold
kf = StratifiedKFold(n_splits=3, random_state=None, shuffle=False) # ì´ìŠˆë¥¼ ë°œìƒì‹œí‚¤ê¸° ìœ„í•˜ì—¬ n_splitsë¥¼ 3ìœ¼ë¡œ ì§€ì •

from sklearn.metrics import accuracy_score

for i, (train_index, valid_index) in enumerate(kf.split(iris_data, iris_target)):
     label_train = df['species'].iloc[train_index]
     label_valid = df['species'].iloc[valid_index]
```

**cross_val_validate()**

```python
from sklearn.model_selection import cross_validate
scores = cross_validate(dt, iris_data, iris_target, cv=5,
                        scoring="accuracy",return_train_score=True,
                         return_estimator=True)
```

**cross_val_score()**

```python
from sklearn.model_selection import cross_val_score
test_score = cross_val_score(dt, iris_data, iris_target, cv=5,
                            scoring="accuracy")
```
