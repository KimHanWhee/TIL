PlayData_MachineLearning (2022/12/12)
===========
ananconda 가상환경 생성

`conda create -n 파일이름 pip python=버전`

실행

`conda activate tf24`

### 텐서플로우 설치

****************************************************`**pip install tensorflow==2.4**`****************************************************

### 케라스 설치

****************************************************`**pip install keras==2.4**`****************************************************

### 주피터 노트북 설치

********************`conda install jupyter notebook`********************

### matplotlib 설치

**********************************************`**conda install matplotlib**`**********************************************

### scikit-learn 설치

******************************************************`pip install scikit-learn`******************************************************

### Scipy 설치

********************************`**pip install scipy**`********************************

## AI

- 인공지능 vs 머신러닝 vs 딥러닝
    - 인공지능>머신러닝>딥러닝
- **머신러닝(기계학습)**
    - 다양한 모델 사용
    - scikit-learn 라이브러리 사용
- **딥러닝**
    - 비정용 (이미지, 소리)
    - 인공 신경망 기반 모델
        - tensorflow
            - DNN
            - CNN(합성곱 인공신경망) : 이미지 분류
            - RNN
            - GAN
        - pytorch
- **머신러닝**
    - 지도학습
        - 분류 : 종류 예측
        - 회귀 : 값 예측
    - 비지도학습
        - 군집화 : 비슷한 것끼리 묶음
        - 차원 축소 : 시각화 가능

## Data종류

**정형**

(머신러닝, scikit-learn)

- 수치
    - 연속형 = 소수점
    - 이산형 = 정수
- 범주
    - 명목형 : 남, 여
    - 순서형(비교가능) : 대>중>소

************비정형************

(딥러닝, tensorflow, pytorch)

- 이미지
- 소리

## scikit-learn

라이브러리 : Machine Learning (ML)

- 클래스 제공
    - Estimator
        - `fit()` : 훈련
        - `predict()` : 예측
        - Classifier
            - 분류 모델 : 종류 예측
        - Regressor
            - 회귀 모델 : 값 예측

## ML실습 순서

1. **데이터 수집**
    - 인터넷 이용(크롤링 포함) ⇒ 결측치, 이상치 O
    - 직접 생성(로컬 Data) ⇒ 결측치, 이상치 O
    - 프레임워크(라이브러리) 제공한 Data ⇒ 결측치, 이상치 X
        - scikit-learn, tensorflow
2. **데이터 전처리**
    - null 처리
    - 이상치 처리
    
    <aside>
    💡 **스케일링(scaling)**
    값의 범위 변경 ⇒ 단위 일치
    
    </aside>
    
    <aside>
    💡 **인코딩(scaling)**
    라벨인코딩 : 영문자 ⇒ 숫자
    **원핫인코딩 : 표현하고 싶은 값을 1로 나머지 0으로**
    
    </aside>
    
3. **데이터 셋 분리**
    - 훈련데이터(Training Data)
    - 평가데이터(Test data)
    
    ************과적합(밑 부분에 자세히 설명)************
    
    - 과대 적합
        - 훈련 Data 정확도가 좋고 그 이외의 Data 정확도가 낮음
    - 과소 적합
        - 훈련 Data와 이외의 Data 정확도가 낮음
    - sklearn의 train_test_split 함수 사용
4. **모델 생성**
    - 클래스 사용
        
        예) x = xxxClassifier()
        
        <aside>
        💡 ****************************파라미터 종류
        하이퍼 파라미터** 
        ⇒ 사용자 지정가능
        
        **모델 파라미터** 
        ⇒ 사용자 지정x
        ⇒ 모델이 훈련(학습)을 통해서 찾아야되는 파라미터
        ⇒ 대표적으로 회귀계수
        
        </aside>
        
5. **모델 학습(훈련)**
    
    `**x.fit(Data(feature), 정답(레이블))**` ⇒ 
    
    - 지도학습
    
    <aside>
    💡 **항상 Data(feature) = 2차원, 정답(레이블) = 1차원**
    
    </aside>
    
    `**x.fit(Data)**` 
    
    - 비지도학습
    - **샘플(sample), DataPoint** : 하나의 **행**
    - **특성(feature)** : 샘플의 속성, 즉 열의 특성을 의미. 통계학에서는 독립변수(설명변수)라고 함.
    - **레이블(label)** = Data(feature)의 값에 대응되는 값
    - **클래스(class)** = 레이블(label)의 종류
6. **예측 및 평가**
    
    `**x.predict()**`
    
    `**score()**`
    

## 과적합

**과대적합(overfitting)**

- 훈련 Data에서만 예측성능이 높고 그 이외의 Data는 예측 성능이 낮은 경우 ⇒ **일반화 성능**이 떨어짐

<aside>
❓ **이유?
-** 훈련을 너무 많이 한 경우
- 모델이 복잡한 경우

</aside>

<aside>
💡 **해결 방안
-** 학습량을 줄인다
- 모델 간소화

분류: 하이퍼 파라미터 수용
회귀: 규제(regularization)
          L2 규제(Ridge) ⇒ 릿지
          L1 규제(Lasso) ⇒ 라쏘
          엘라스틱넷(elastic net) ⇒ L2 + L1

</aside>

******************************과소적합(underfitting)******************************

- 훈련 Data 및 이외 Data 모두 예측 성능이 낮은 경우

<aside>
❓ **이유?**
- 훈련을 너무 적게 한 경우(Data가 적은 경우)
- 모델 간소화 경우

</aside>

<aside>
💡 **해결 방안
-** 학습량을 늘린다
- 모델 복잡화

</aside>

### 규제(과대적합 방지)

- **L2 규제(Ridge)**
    - 회귀 계수 값은 **0으로 근접**. 값 결정에 미미함.
- **L1 규제(Lasso)**
    - 회귀 계수 값을 **0으로 만들어버림**.
- **엘라스틱넷(elastic net)**
    - L2 + L1

### 회귀(Regression)

- 값 예측
- 직선(기울기와 절편)을 잘 그리면 된다

<aside>
💡 y = w1(기울기)x+w0(절편)

**feature가 여러개가 되는 경우**
 ⇒ ****y = w1x1 + w2x2 + w3x3 + w4x4 + … + w0

</aside>
